/*
 * Copyright (c) 2003 Matteo Frigo
 * Copyright (c) 2003 Massachusetts Institute of Technology
 *
 * This program is free software; you can redistribute it and/or modify
 * it under the terms of the GNU General Public License as published by
 * the Free Software Foundation; either version 2 of the License, or
 * (at your option) any later version.
 *
 * This program is distributed in the hope that it will be useful,
 * but WITHOUT ANY WARRANTY; without even the implied warranty of
 * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
 * GNU General Public License for more details.
 *
 * You should have received a copy of the GNU General Public License
 * along with this program; if not, write to the Free Software
 * Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA  02111-1307  USA
 *
 */

/* This file was automatically generated --- DO NOT EDIT */
/* Generated on Sat Jul  5 21:52:47 EDT 2003 */

#include "config.h"



/* cheap-mode: VECTGRADE_FULL succeeded. (388 steps) */
/* Generated by: /homee/stevenj/cvs/fftw3.0.1/genfft-k7/gen_twiddle -no-randomized-cse -dif -n 16 -name f1k7_16 */

/*
 * Generator Id's : 
 * $Id: algsimp.ml,v 1.3 2003/03/15 20:29:42 stevenj Exp $
 * $Id: fft.ml,v 1.3 2003/03/15 20:29:43 stevenj Exp $
 * $Id: gen_twiddle.ml,v 1.13 2003/04/18 01:21:45 athena Exp $
 */

/* The following asm code is Copyright (c) 2000-2001 Stefan Kral */
.section .rodata
	.balign 64
chs_hi: .long 0x00000000, 0x80000000
chs_lo: .long 0x80000000, 0x00000000
KP707106781KP707106781: .float +0.707106781186547524400844362104849039284835938, +0.707106781186547524400844362104849039284835938
KP923879532KP382683432: .float +0.923879532511286756128183189396788286822416626, +0.382683432365089771728459984030398866761344562
KP382683432KP923879532: .float +0.382683432365089771728459984030398866761344562, +0.923879532511286756128183189396788286822416626
.text
.text
	.balign 64
f1k7_16:
	subl $244, %esp
	femms 
	movl %ebx, 240(%esp)
	movl 260(%esp), %edx
	movl 268(%esp), %ebx
	movl 248(%esp), %ecx
	movl %esi, 236(%esp)
	movl 256(%esp), %eax
	movl %edi, 232(%esp)
	movl 264(%esp), %esi
	movl %ebp, 228(%esp)
	leal (,%edx,4), %edx
	leal (,%ebx,4), %ebx
	.p2align 4,,7
.L0:
	/* promise simd cell size = 8 */ 
	movq (%ecx,%edx,8), %mm0
	movq (%ecx), %mm1
	leal (%edx,%edx,2), %edi
	movq (%ecx,%edx,4), %mm4
	movq (%ecx,%edi,4), %mm3
	leal (%edi,%edx,4), %ebp
	movq %mm1, %mm2
	pfadd %mm0, %mm1
	movq %mm4, %mm5
	leal (%ebp,%edx,8), %edi
	movq (%ecx,%ebp), %mm7
	pfsub %mm0, %mm2
	pfadd %mm3, %mm4
	movq (%ecx,%edi), %mm0
	leal (%ebp,%edx,4), %edi
	leal (%edx,%edx,2), %ebp
	movq %mm1, %mm6
	pfsub %mm3, %mm5
	movq %mm2, 16(%esp)
	movq (%ecx,%edi), %mm2
	leal (%edx,%edx,4), %edi
	pfsub %mm4, %mm1
	movq %mm0, %mm3
	pfadd %mm4, %mm6
	movq %mm5, 24(%esp)
	movq (%ecx,%ebp), %mm4
	pfadd %mm7, %mm0
	pfsub %mm7, %mm3
	movq %mm1, 64(%esp)
	movq (%ecx,%edi,2), %mm1
	movq %mm4, %mm5
	pfsub %mm2, %mm4
	movq %mm0, %mm7
	pfadd %mm2, %mm5
	movq %mm3, 0(%esp)
	movq %mm4, 8(%esp)
	movq (%ecx,%edx,2), %mm2
	movq (%ecx,%ebp,2), %mm4
	leal (%edi,%edx,2), %ebp
	leal (%edx,%edx,8), %edi
	pfadd %mm5, %mm7
	movq %mm2, %mm3
	pfsub %mm5, %mm0
	movq (%ecx,%ebp,2), %mm5
	leal (%edi,%edx,4), %ebp
	pfsub %mm1, %mm2
	pfadd %mm1, %mm3
	movq %mm5, %mm1
	pfsub %mm4, %mm5
	movq %mm0, 32(%esp)
	pfadd %mm4, %mm1
	movq %mm3, %mm4
	movq %mm5, %mm0
	pfpnacc %mm2, %mm0
	pswapd %mm2, %mm2
	pfadd %mm1, %mm4
	pfpnacc %mm5, %mm2
	movq (%ecx,%edx), %mm5
	pfsub %mm1, %mm3
	movq (%ecx,%edi), %mm1
	leal (%edx,%edx,4), %edi
	movq %mm0, 40(%esp)
	movq %mm5, %mm0
	movq %mm2, 48(%esp)
	movq (%ecx,%ebp), %mm2
	pfsub %mm1, %mm5
	pswapd %mm3, %mm3
	leal (%edx,%edx,2), %ebp
	pfadd %mm1, %mm0
	pxor chs_hi, %mm3
	movq (%ecx,%edi), %mm1
	leal (%ebp,%edx,8), %edi
	movq %mm5, 56(%esp)
	leal (%edi,%edx,4), %ebp
	movq %mm1, %mm5
	pfadd %mm2, %mm1
	pfsub %mm2, %mm5
	movq %mm0, %mm2
	pfadd %mm1, %mm0
	pfsub %mm1, %mm2
	movq %mm6, %mm1
	pfadd %mm4, %mm6
	pxor chs_lo, %mm5
	pfsub %mm4, %mm1
	movq %mm0, %mm4
	pfsub %mm7, %mm0
	pfadd %mm7, %mm4
	movq %mm6, %mm7
	movq %mm1, 80(%esp)
	movq %mm0, 88(%esp)
	movq 64(%esp), %mm1
	pfsub %mm4, %mm6
	pfadd %mm4, %mm7
	movq %mm1, %mm0
	movq 32(%esp), %mm4
	pfsub %mm3, %mm1
	pfadd %mm3, %mm0
	pswapd %mm2, %mm3
	movq %mm6, 144(%esp)
	pfpnacc %mm4, %mm3
	movq %mm7, 72(%esp)
	movq 48(%esp), %mm7
	pfpnacc %mm2, %mm4
	movq %mm1, 120(%esp)
	movq %mm0, 104(%esp)
	movq 40(%esp), %mm2
	movq 24(%esp), %mm0
	movq %mm3, %mm6
	movq %mm7, %mm1
	pfnacc %mm4, %mm3
	pfacc %mm6, %mm4
	pswapd %mm0, %mm0
	movq 16(%esp), %mm6
	pfnacc %mm2, %mm7
	pxor chs_lo, %mm0
	pfacc %mm1, %mm2
	pfmul KP707106781KP707106781, %mm3
	pfmul KP707106781KP707106781, %mm4
	movq %mm6, %mm1
	pfmul KP707106781KP707106781, %mm7
	pfadd %mm0, %mm1
	pfmul KP707106781KP707106781, %mm2
	pfsub %mm0, %mm6
	movq %mm3, 112(%esp)
	movq %mm4, 96(%esp)
	movq 56(%esp), %mm0
	movq %mm1, %mm4
	movq %mm6, %mm3
	pswapd %mm0, %mm0
	pfadd %mm7, %mm1
	pfsub %mm7, %mm4
	pfadd %mm2, %mm6
	pfsub %mm2, %mm3
	movq %mm0, %mm2
	pfsub %mm5, %mm0
	movq %mm1, 128(%esp)
	movq %mm4, 136(%esp)
	movq 8(%esp), %mm4
	pfadd %mm5, %mm2
	movq 0(%esp), %mm5
	movq %mm0, %mm7
	pfmul KP923879532KP382683432, %mm0
	pswapd %mm4, %mm4
	movq %mm5, %mm1
	pfmul KP382683432KP923879532, %mm7
	pxor chs_lo, %mm4
	pfadd %mm4, %mm5
	pfsub %mm4, %mm1
	movq %mm5, %mm4
	pfmul KP923879532KP382683432, %mm5
	pfmul KP382683432KP923879532, %mm4
	pfpnacc %mm5, %mm7
	movq %mm2, %mm5
	pfmul KP382683432KP923879532, %mm2
	pfpnacc %mm0, %mm4
	movq %mm1, %mm0
	pfmul KP923879532KP382683432, %mm5
	pfmul KP923879532KP382683432, %mm1
	pfmul KP382683432KP923879532, %mm0
	pfpnacc %mm2, %mm1
	pfpnacc %mm0, %mm5
	movq %mm3, %mm0
	movq %mm5, %mm2
	pfnacc %mm1, %mm5
	pfacc %mm2, %mm1
	movq 96(%eax), %mm2
	pfsub %mm5, %mm3
	pfadd %mm5, %mm0
	pswapd %mm3, %mm5
	pfmul %mm2, %mm3
	pfmul %mm2, %mm5
	movq 32(%eax), %mm2
	pfpnacc %mm3, %mm5
	pswapd %mm0, %mm3
	pfmul %mm2, %mm0
	pfmul %mm2, %mm3
	movq %mm6, %mm2
	pfsub %mm1, %mm6
	pfadd %mm1, %mm2
	movq %mm5, 160(%esp)
	movq 64(%eax), %mm1
	pfpnacc %mm0, %mm3
	pswapd %mm6, %mm5
	movq %mm7, %mm0
	pfnacc %mm4, %mm7
	pfmul %mm1, %mm6
	pfacc %mm0, %mm4
	movq 144(%esp), %mm0
	pfmul %mm1, %mm5
	movq %mm3, 152(%esp)
	movq (%eax), %mm1
	pswapd %mm2, %mm3
	pfmul %mm1, %mm2
	pfpnacc %mm6, %mm5
	pfmul %mm1, %mm3
	movq 56(%eax), %mm1
	pswapd %mm0, %mm6
	movq %mm5, 176(%esp)
	pfpnacc %mm2, %mm3
	movq 136(%esp), %mm2
	pfmul %mm1, %mm0
	pfmul %mm1, %mm6
	movq 112(%eax), %mm1
	movq %mm2, %mm5
	pfadd %mm7, %mm2
	movq %mm3, 168(%esp)
	movq 48(%eax), %mm3
	pfpnacc %mm0, %mm6
	pfsub %mm7, %mm5
	pswapd %mm2, %mm0
	pfmul %mm3, %mm2
	pswapd %mm6, %mm6
	pfmul %mm3, %mm0
	movq 128(%esp), %mm3
	pswapd %mm5, %mm7
	pfmul %mm1, %mm5
	pfmul %mm1, %mm7
	movq %mm3, %mm1
	pfpnacc %mm2, %mm0
	movq 80(%eax), %mm2
	pfsub %mm4, %mm3
	pfadd %mm4, %mm1
	pfpnacc %mm5, %mm7
	movq %mm0, 216(%esp)
	movq 16(%eax), %mm5
	pswapd %mm3, %mm4
	pfmul %mm2, %mm3
	pswapd %mm1, %mm0
	pfmul %mm5, %mm1
	pswapd %mm7, %mm7
	pfmul %mm2, %mm4
	movq 120(%esp), %mm2
	pfmul %mm5, %mm0
	movq 112(%esp), %mm5
	pfpnacc %mm3, %mm4
	movq %mm2, %mm3
	pfsub %mm5, %mm2
	pfpnacc %mm1, %mm0
	movq 104(%eax), %mm1
	pfadd %mm5, %mm3
	pswapd %mm4, %mm4
	pswapd %mm2, %mm5
	movq %mm0, 184(%esp)
	pfmul %mm1, %mm2
	movq 40(%eax), %mm0
	pfmul %mm1, %mm5
	pswapd %mm3, %mm1
	pfmul %mm0, %mm3
	pfmul %mm0, %mm1
	pfpnacc %mm2, %mm5
	movq 104(%esp), %mm0
	movq 96(%esp), %mm2
	pfpnacc %mm3, %mm1
	movq %mm0, %mm3
	movq %mm5, 200(%esp)
	pfsub %mm2, %mm0
	movq 72(%eax), %mm5
	pfadd %mm2, %mm3
	movq %mm1, 192(%esp)
	movq 8(%eax), %mm1
	pswapd %mm0, %mm2
	pfmul %mm5, %mm0
	pfmul %mm5, %mm2
	pswapd %mm3, %mm5
	pfmul %mm1, %mm3
	pfmul %mm1, %mm5
	movq 88(%esp), %mm1
	pfpnacc %mm0, %mm2
	movq 80(%esp), %mm0
	pswapd %mm1, %mm1
	pfpnacc %mm3, %mm5
	pxor chs_hi, %mm1
	movq %mm0, %mm3
	movq %mm2, 208(%esp)
	movq 24(%eax), %mm2
	pswapd %mm5, %mm5
	pfadd %mm1, %mm0
	pfsub %mm1, %mm3
	pswapd %mm0, %mm1
	pfmul %mm2, %mm0
	pfmul %mm2, %mm1
	movq 72(%esp), %mm2
	pfpnacc %mm0, %mm1
	movq 88(%eax), %mm0
	/* simd data load/store barrier */ 
	movq %mm2, (%ecx)
	pswapd %mm3, %mm2
	addl $120, %eax
	movq %mm4, (%ecx,%edi)
	movq 216(%esp), %mm4
	leal (%edx,%edx,2), %edi
	movq %mm6, (%ecx,%edx,8)
	movq 208(%esp), %mm6
	pfmul %mm0, %mm3
	movq %mm7, (%ecx,%ebp)
	leal (%edx,%edi,2), %ebp
	pfmul %mm0, %mm2
	movq 184(%esp), %mm7
	pswapd %mm1, %mm1
	pswapd %mm4, %mm4
	movq 152(%esp), %mm0
	movq %mm5, (%ecx,%edx,2)
	pswapd %mm6, %mm6
	movq 168(%esp), %mm5
	movq %mm1, (%ecx,%edx,4)
	movq %mm4, (%ecx,%ebp)
	movq 176(%esp), %mm4
	leal (%edx,%edx,4), %ebp
	pfpnacc %mm3, %mm2
	pswapd %mm7, %mm7
	movq 160(%esp), %mm3
	movq 200(%esp), %mm1
	movq %mm6, (%ecx,%ebp,2)
	pswapd %mm0, %mm0
	movq 192(%esp), %mm6
	movq %mm7, (%ecx,%edi)
	pswapd %mm5, %mm5
	pswapd %mm4, %mm4
	movq %mm0, (%ecx,%ebp)
	pswapd %mm2, %mm2
	pswapd %mm3, %mm3
	movq %mm5, (%ecx,%edx)
	pswapd %mm1, %mm1
	movq %mm2, (%ecx,%edi,4)
	leal (%edx,%edx,8), %edi
	pswapd %mm6, %mm6
	movq %mm4, (%ecx,%edi)
	leal (%ebp,%edx,8), %edi
	movq %mm3, (%ecx,%edi)
	leal (%ebp,%edx,2), %edi
	leal (%edx,%edx,2), %ebp
	movq %mm1, (%ecx,%edi,2)
	movq %mm6, (%ecx,%ebp,2)
	addl %ebx, %ecx
	decl %esi
	jnz .L0
	femms 
	movl 240(%esp), %ebx
	movl 236(%esp), %esi
	movl 232(%esp), %edi
	movl 228(%esp), %ebp
	addl $244, %esp
	ret 

.section .rodata
nam:
	.string "f1k7_16"
	.align 4
twinstr:
	.byte 4
	.byte 0
	.value 16
	.byte 3
	.byte 1
	.value 0
	.align 4
desc:
	.long 16
	.long nam
	.long twinstr
	.zero 4
	.double 87
	.double 42
	.double 0
	.double 0
	.long fftwf_kdft_ct_k7_mgenus
	.long 0
	.long 0
	.long 0

.text
	.align 4
.globl fftwf_codelet_f1k7_16
fftwf_codelet_f1k7_16:
	subl $12,%esp
	movl 16(%esp),%eax
	addl $-4,%esp
	pushl $desc
	pushl $f1k7_16
	pushl %eax
	call fftwf_kdft_dif_register
	addl $16,%esp
	addl $12,%esp
	ret

